{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LWmhvQY_Casx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from geopy.distance import geodesic"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and Process CSVS"
      ],
      "metadata": {
        "id": "RLaSM-YrDqLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_paths = glob.glob('./*.csv')\n",
        "df_list = []\n",
        "\n",
        "for path in csv_paths:\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        required_cols = {\n",
        "            'timestamp', 'mode', 'duration_seconds', 'duration_in_traffic',\n",
        "            'origin_lat', 'origin_lng', 'destination_lat', 'destination_lng'\n",
        "        }\n",
        "        if required_cols.issubset(df.columns):\n",
        "            df = df.copy()\n",
        "            df['duration_final'] = df.apply(\n",
        "                lambda row: row['duration_in_traffic'] if row['mode'] == 'driving' else row['duration_seconds'],\n",
        "                axis=1\n",
        "            )\n",
        "            df['geo_distance'] = df.apply(lambda row: geodesic(\n",
        "                (row['origin_lat'], row['origin_lng']),\n",
        "                (row['destination_lat'], row['destination_lng'])\n",
        "            ).meters, axis=1)\n",
        "            df_list.append(df)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load {path}: {e}\")\n",
        "\n",
        "if not df_list:\n",
        "    raise ValueError(\"No valid CSVs found.\")\n",
        "\n",
        "full_df = pd.concat(df_list, ignore_index=True)"
      ],
      "metadata": {
        "id": "FafzCFZbD0nH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering"
      ],
      "metadata": {
        "id": "8BqG-Z_IyV-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_df['datetime'] = pd.to_datetime(full_df['timestamp'], unit='s')\n",
        "full_df['hour_of_day'] = full_df['datetime'].dt.hour\n",
        "full_df['day_of_week'] = full_df['datetime'].dt.dayofweek  # Monday = 0\n",
        "\n",
        "# Drop missing values\n",
        "full_df.dropna(subset=['duration_final', 'geo_distance'], inplace=True)\n",
        "\n",
        "# One-hot encode mode only\n",
        "full_df = pd.get_dummies(full_df, columns=['mode'])\n",
        "\n",
        "# Define feature set\n",
        "features = [\n",
        "    'hour_of_day', 'day_of_week', 'geo_distance',\n",
        "    'origin_lat', 'origin_lng', 'destination_lat', 'destination_lng'\n",
        "] + [col for col in full_df.columns if col.startswith('mode_')]\n",
        "\n",
        "X = full_df[features]\n",
        "y = full_df['duration_final']"
      ],
      "metadata": {
        "id": "KPHn4S9FyXPA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train / Test split with Model Training"
      ],
      "metadata": {
        "id": "wzbd1ldiy5lE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Model evaluation ===\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Performance:\")\n",
        "print(f\"MAE: {mae:.2f} seconds\")\n",
        "print(f\"R² Score: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYBYL3NPy8Zt",
        "outputId": "8c845a0d-2a0d-4067-8f62-450681f35498"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance:\n",
            "MAE: 12.77 seconds\n",
            "R² Score: 0.9916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction Utility"
      ],
      "metadata": {
        "id": "yU_JYgISy-5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_sample_geo(origin, destination, mode, hour, day, model_columns):\n",
        "\n",
        "    if not (6 <= hour <= 22):\n",
        "        raise ValueError(f\"Invalid hour: {hour}. Must be between 0 and 23.\")\n",
        "    if not (0 <= day <= 6):\n",
        "        raise ValueError(f\"Invalid day: {day}. Must be between 0 (Mon) and 6 (Sun).\")\n",
        "\n",
        "    data = {\n",
        "        'hour_of_day': hour,\n",
        "        'day_of_week': day,\n",
        "        'origin_lat': origin[0],\n",
        "        'origin_lng': origin[1],\n",
        "        'destination_lat': destination[0],\n",
        "        'destination_lng': destination[1],\n",
        "    }\n",
        "    data['geo_distance'] = geodesic(origin, destination).meters\n",
        "\n",
        "    for m in ['bicycling', 'driving', 'transit', 'walking']:\n",
        "        data[f'mode_{m}'] = 1 if m == mode else 0\n",
        "\n",
        "    sample_df = pd.DataFrame([data])\n",
        "    for col in model_columns:\n",
        "        if col not in sample_df.columns:\n",
        "            sample_df[col] = 0\n",
        "    sample_df = sample_df[model_columns]\n",
        "\n",
        "    return sample_df\n"
      ],
      "metadata": {
        "id": "miWYjFRzzAS-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example Prediction"
      ],
      "metadata": {
        "id": "lVWKGoa9zC6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "origin = (47.6205, -122.3492)  # Space Needle\n",
        "destination = (47.6116, -122.3375)  # Westlake Park\n",
        "sample = build_sample_geo(origin, destination, mode='driving', hour=9, day=3, model_columns=X.columns)\n",
        "pred = model.predict(sample)\n",
        "print(f\"Predicted travel time: {pred[0]:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN8RvafTzEme",
        "outputId": "714dbb64-f208-4c12-d03e-0f3f69785267"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted travel time: 396.92 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save THE MODEL"
      ],
      "metadata": {
        "id": "gf9TpCfC8GPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model and feature column list\n",
        "joblib.dump(model, 'travel_time_model.pkl')\n",
        "joblib.dump(X.columns.tolist(), 'model_columns.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XkWeqil8ItU",
        "outputId": "c43c2010-9d75-4b3c-e023-d2e090daa828"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_columns.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}